{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Delays.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"kCkJGqv3rQ62","colab_type":"text"},"source":["## Exploratory Data Analysis for 2009 - 2015 Flight Delays and cancellations"]},{"cell_type":"markdown","metadata":{"id":"w0L6AFH4rQ64","colab_type":"text"},"source":["####  Data Profiling "]},{"cell_type":"markdown","metadata":{"id":"1_gdyiA7rQ68","colab_type":"text"},"source":["##### Import required libraries"]},{"cell_type":"code","metadata":{"id":"sKRngZF0rQ69","colab_type":"code","colab":{}},"source":["import findspark\n","findspark.init()\n","\n","import pyspark\n","from pyspark.sql.session import SparkSession\n","sc = pyspark.SparkContext(appName=\"myAppName2\").getOrCreate()\n","spark = SparkSession(sc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-Vx2ABMrQ7C","colab_type":"code","colab":{}},"source":["from pyspark.sql.types import *\n","from pyspark.sql import functions as F \n","from pyspark.sql.functions import isnan, when, count, col\n","import pandas as pd "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qGPTQSA6rQ7J","colab_type":"text"},"source":["##### Create Schema"]},{"cell_type":"markdown","metadata":{"id":"Bc2_50u_rQ7J","colab_type":"text"},"source":["##### Flight Profile"]},{"cell_type":"markdown","metadata":{"id":"CeXo-DiYrQ7K","colab_type":"text"},"source":["##### Chunking Data"]},{"cell_type":"markdown","metadata":{"id":"ZwWj1-6CrQ7L","colab_type":"text"},"source":["Our null analysis shows that the following features have a lot of null values: We will delete these rows, and omit some unnecessary columns as well. "]},{"cell_type":"markdown","metadata":{"id":"xa7uyVMqrQ7M","colab_type":"text"},"source":["Verifying that there are no more null columns"]},{"cell_type":"markdown","metadata":{"id":"r1ljWZU5rQ7M","colab_type":"text"},"source":["##### Flight delays"]},{"cell_type":"code","metadata":{"id":"UHM_B2RtrQ7N","colab_type":"code","colab":{}},"source":["delay_schema = StructType([StructField('date', StringType(), True),\n","                     StructField('flight_identifier', StringType(), True),\n","                     StructField('plan_time', StringType(), True),\n","                     StructField('actual_time', StringType(), True),\n","                     StructField('dep_delay', IntegerType(), True)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHmDN9PnrQ7R","colab_type":"code","colab":{},"outputId":"b19b44ae-c908-4f49-a359-6edf9da680f1"},"source":["delay_df = spark.read.format('csv').load('flight-delays.csv', header='true', schema=delay_schema) \n","delay_df = delay_df.drop('actual_time')\n","delay_df = delay_df.drop('plan_time')\n","delay_df = delay_df.sample(.1)\n","delay_df = delay_df.dropna()\n","delay_df.printSchema()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["root\n"," |-- date: string (nullable = true)\n"," |-- flight_identifier: string (nullable = true)\n"," |-- dep_delay: integer (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-JOKXxdarQ7e","colab_type":"code","colab":{},"outputId":"5017a7d6-061f-4a5b-d37c-75a148ff9288"},"source":["delay_df.show(10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----+-----------------+---------+\n","|date|flight_identifier|dep_delay|\n","+----+-----------------+---------+\n","|2009|               XE|       -5|\n","|2009|               XE|       -4|\n","|2009|               XE|       -7|\n","|2009|               XE|       -5|\n","|2009|               XE|       25|\n","|2009|               XE|       -6|\n","|2009|               XE|       -1|\n","|2009|               XE|       -2|\n","|2009|               XE|       -4|\n","|2009|               XE|       -1|\n","+----+-----------------+---------+\n","only showing top 10 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vgLgwNfqrQ7i","colab_type":"code","colab":{},"outputId":"b83b951a-8a4a-4d73-9556-246758f8bb9d"},"source":["delay_df.count()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5461231"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Da4bmwKJrQ7r","colab_type":"code","colab":{}},"source":["from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n","categoricalColumns = [\"date\", \"flight_identifier\"]\n","#indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\").fit(delay_df) for column in [\"date\", \"flight_number\", \"flight_identifier\", \"delay\", \"reason\"]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IC5Y1xSArQ7v","colab_type":"code","colab":{},"outputId":"ae0ee782-a840-4df5-c524-f5eefb01dc57"},"source":["from pyspark.ml import Pipeline\n","from pyspark.ml.feature import StringIndexer\n","indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(delay_df) for column in categoricalColumns]\n","pipeline = Pipeline(stages=indexers)\n","delay2 = pipeline.fit(delay_df).transform(delay_df)\n","delay2.show(10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----+-----------------+---------+----------+-----------------------+\n","|date|flight_identifier|dep_delay|date_index|flight_identifier_index|\n","+----+-----------------+---------+----------+-----------------------+\n","|2009|               XE|       -5|       1.0|                   10.0|\n","|2009|               XE|       -4|       1.0|                   10.0|\n","|2009|               XE|       -7|       1.0|                   10.0|\n","|2009|               XE|       -5|       1.0|                   10.0|\n","|2009|               XE|       25|       1.0|                   10.0|\n","|2009|               XE|       -6|       1.0|                   10.0|\n","|2009|               XE|       -1|       1.0|                   10.0|\n","|2009|               XE|       -2|       1.0|                   10.0|\n","|2009|               XE|       -4|       1.0|                   10.0|\n","|2009|               XE|       -1|       1.0|                   10.0|\n","+----+-----------------+---------+----------+-----------------------+\n","only showing top 10 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jCSdL-IFrQ7x","colab_type":"code","colab":{}},"source":["#from pyspark.ml.feature import OneHotEncoder, StringIndexer\n","#indexers_ON = [OneHotEncoder(inputCol=column, outputCol=column+\"_Vec\") for column in filter(lambda x: x.endswith('_index'), delay2.columns) ]\n","#pipeline = Pipeline(stages=indexers_ON)\n","#delay2 = pipeline.fit(delay2).transform(delay2)\n","#delay2.show(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y7cq-CdgrQ70","colab_type":"code","colab":{},"outputId":"b430be7d-b4dd-44dd-87e1-7bf9cbb97812"},"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.classification import RandomForestClassifier\n","\n","#assemblerInputs = ['date_index','flight_identifier_index']\n","assembler = VectorAssembler(inputCols=['date_index','flight_identifier_index'], outputCol=\"features\")\n","delay3 = assembler.transform(delay2)\n","delay3 = delay3.select(['features', 'dep_delay'])\n","delay3.show(10)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----------+---------+\n","|  features|dep_delay|\n","+----------+---------+\n","|[1.0,10.0]|       -5|\n","|[1.0,10.0]|       -4|\n","|[1.0,10.0]|       -7|\n","|[1.0,10.0]|       -5|\n","|[1.0,10.0]|       25|\n","|[1.0,10.0]|       -6|\n","|[1.0,10.0]|       -1|\n","|[1.0,10.0]|       -2|\n","|[1.0,10.0]|       -4|\n","|[1.0,10.0]|       -1|\n","+----------+---------+\n","only showing top 10 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jr1XlX_rrQ75","colab_type":"code","colab":{}},"source":["splits = delay3.randomSplit([0.7, 0.3])\n","train_df = splits[0]\n","test_df = splits[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XpT16mf3rQ79","colab_type":"code","colab":{},"outputId":"5b80fd8e-1b14-4864-e0e3-3f91b421bccb"},"source":["from pyspark.ml.regression import LinearRegression\n","lr = LinearRegression(featuresCol = 'features', labelCol='dep_delay', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n","lr_model = lr.fit(train_df)\n","print(\"Coefficients: \" + str(lr_model.coefficients))\n","print(\"Intercept: \" + str(lr_model.intercept))\n","lr_predictions = lr_model.transform(test_df)\n","lr_predictions.select(\"prediction\",\"dep_delay\",\"features\").show(5)\n","from pyspark.ml.evaluation import RegressionEvaluator\n","lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n","                 labelCol=\"dep_delay\",metricName=\"rmse\")\n","print(\"Root Mean Squared Error (RMSE) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Coefficients: [0.0,-0.08711292664978186]\n","Intercept: 9.594737106457627\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <function JavaWrapper.__del__ at 0x7f913005b200>\n","Traceback (most recent call last):\n","  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 40, in __del__\n","    if SparkContext._active_spark_context and self._java_obj is not None:\n","AttributeError: 'RandomForestClassifier' object has no attribute '_java_obj'\n"],"name":"stderr"},{"output_type":"stream","text":["+-----------------+---------+---------+\n","|       prediction|dep_delay| features|\n","+-----------------+---------+---------+\n","|9.594737106457627|      -15|[1.0,0.0]|\n","|9.594737106457627|      -13|[1.0,0.0]|\n","|9.594737106457627|      -11|[1.0,0.0]|\n","|9.594737106457627|      -10|[1.0,0.0]|\n","|9.594737106457627|      -10|[1.0,0.0]|\n","+-----------------+---------+---------+\n","only showing top 5 rows\n","\n","Root Mean Squared Error (RMSE) on test data = 37.4283\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yrsxAiHorQ8C","colab_type":"code","colab":{},"outputId":"2c7845b4-b79c-442a-bd84-7e70f0ae4a39"},"source":["from pyspark.ml.regression import DecisionTreeRegressor\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'dep_delay')\n","dt_model = dt.fit(train_df)\n","dt_predictions = dt_model.transform(test_df)\n","dt_evaluator = RegressionEvaluator(\n","    labelCol=\"dep_delay\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = dt_evaluator.evaluate(dt_predictions)\n","print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Root Mean Squared Error (RMSE) on test data = 37.3293\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iAE7rXOirQ8F","colab_type":"code","colab":{}},"source":["trainingSummary = lr_model.summary\n","print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n","print(\"r2: %f\" % trainingSummary.r2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2V2W1XpFrQ8J","colab_type":"code","colab":{}},"source":["train, test = delay_df.randomSplit([0.7, 0.3], seed = 2018)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CAVgy-cZrQ8N","colab_type":"code","colab":{}},"source":["from pyspark.ml.classification import LogisticRegression\n","lr = LogisticRegression(featuresCol = 'features', labelCol = 'label')\n","lrModel = lr.fit(train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wMTJ9f6rQ8R","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","beta = np.sort(lrModel.coefficients)\n","plt.plot(beta)\n","plt.ylabel('Beta Coefficients')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7W5OZmVcrQ8T","colab_type":"code","colab":{}},"source":["trainingSummary = lrModel.summary\n","roc = trainingSummary.roc.toPandas()\n","plt.plot(roc['FPR'],roc['TPR'])\n","plt.ylabel('False Positive Rate')\n","plt.xlabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.show()\n","print('Training set area under ROC: ' + str(trainingSummary.areaUnderROC))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B5QRPyJSrQ8V","colab_type":"code","colab":{}},"source":["pr = trainingSummary.pr.toPandas()\n","plt.plot(pr['recall'],pr['precision'])\n","plt.ylabel('Precision')\n","plt.xlabel('Recall')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jo6hc06ZrQ8Z","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","predictions = lrModel.transform(test)\n","\n","predictions.select('date',\n"," 'flight_number',\n"," 'flight_identifier', 'prediction', 'probability').show(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRsQVpaErQ8b","colab_type":"code","colab":{}},"source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","evaluator = BinaryClassificationEvaluator()\n","print('Test Area Under ROC', evaluator.evaluate(predictions))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ByHM1mfrQ8e","colab_type":"code","colab":{}},"source":["from pyspark.ml.classification import DecisionTreeClassifier\n","dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n","dtModel = dt.fit(train)\n","predictions = dtModel.transform(test)\n","predictions.select('date',\n"," 'flight_number',\n"," 'flight_identifier', 'prediction', 'probability').show(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jjP-uRIkrQ8h","colab_type":"code","colab":{}},"source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","evaluator = BinaryClassificationEvaluator()\n","print('Test Area Under ROC', evaluator.evaluate(predictions))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TXg5JJ4HrQ8k","colab_type":"code","colab":{}},"source":["from pyspark.ml.classification import RandomForestClassifier\n","rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n","rfModel = rf.fit(train)\n","predictions = rfModel.transform(test)\n","predictions.select('date',\n"," 'flight_number',\n"," 'flight_identifier', 'prediction', 'probability').show(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0RgfirbrQ8o","colab_type":"code","colab":{}},"source":["evaluator = BinaryClassificationEvaluator()\n","print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxAWh7TdrQ8r","colab_type":"code","colab":{}},"source":["from pyspark.ml.classification import GBTClassifier\n","gbt = GBTClassifier(maxIter=10)\n","gbtModel = gbt.fit(train)\n","predictions = gbtModel.transform(test)\n","predictions.select('date',\n"," 'flight_number',\n"," 'flight_identifier', 'prediction', 'probability').show(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJYV19zkrQ8t","colab_type":"code","colab":{}},"source":["evaluator = BinaryClassificationEvaluator()\n","print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sjaN-N6_rQ8v","colab_type":"text"},"source":["##### Flight Delays"]},{"cell_type":"code","metadata":{"id":"phOS_q__rQ8v","colab_type":"code","colab":{}},"source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","paramGrid = (ParamGridBuilder()\n","             .addGrid(gbt.maxDepth, [2, 4, 6])\n","             .addGrid(gbt.maxBins, [20, 60])\n","             .build())\n","cv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\n","cvModel = cv.fit(train)\n","predictions = cvModel.transform(test)\n","evaluator.evaluate(predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWwvm14ArQ8x","colab_type":"code","colab":{}},"source":["cvModel.bestModel"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDXikYSnrQ81","colab_type":"code","colab":{}},"source":["cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]\n"],"execution_count":0,"outputs":[]}]}